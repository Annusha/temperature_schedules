{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cbcc382",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '../datasets/ILSVRC2012/'\n",
    "ckp_root = '../checkpoints/imagenet100/'\n",
    "code_root = '../'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import colors\n",
    "from collections import Counter, defaultdict\n",
    "from numpy import linalg as LA\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import LinearSVC\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import sys\n",
    "sys.path.append(code_root)\n",
    "from models.resnet import resnet50\n",
    "from utils import cvt_state_dict\n",
    "from data.LT_Dataset import LT_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7144b764-9731-4340-b6a4-56352dad0434",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "          transforms.RandomResizedCrop(224),\n",
    "          transforms.RandomHorizontalFlip(),\n",
    "          transforms.ToTensor(),\n",
    "      ])\n",
    "transform_test = transforms.Compose([\n",
    "          transforms.Resize(256),\n",
    "          transforms.CenterCrop(224),\n",
    "          transforms.ToTensor(),\n",
    "      ])\n",
    "\n",
    "txt_test = code_root + \"split/imagenet-100/ImageNet_100_test.txt\"\n",
    "txt_train_lt = code_root + \"split/imagenet-100/imageNet_100_LT_train.txt\"\n",
    "txt_train_fs = code_root + \"split/imagenet-100/imageNet_100_sub_balance_train_0.01.txt\"\n",
    "\n",
    "\n",
    "train_datasets_lt = LT_Dataset(root=data_root, txt=txt_train_lt, transform=transform_test)\n",
    "train_datasets_fs = LT_Dataset(root=data_root, txt=txt_train_fs, transform=transform_test)\n",
    "test_datasets = LT_Dataset(root=data_root, txt=txt_test, transform=transform_test)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "train_loader_lt = torch.utils.data.DataLoader(train_datasets_lt, num_workers=0, batch_size=batch_size)\n",
    "train_loader_fs = torch.utils.data.DataLoader(train_datasets_fs, num_workers=0, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_datasets, num_workers=0, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af58e921-0ebe-4328-a1da-605f5b01b9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_class = 100\n",
    "bnNameCnt = -1\n",
    "device = 'cuda'\n",
    "model = resnet50(num_classes=num_class, imagenet='imagenet-100')\n",
    "model = model.to(device)\n",
    "\n",
    "path_checkpoint = ckp_root + f'simclr_TS.pt'\n",
    "checkpoint = torch.load(path_checkpoint, map_location=\"cpu\")\n",
    "if 'state_dict' in checkpoint:\n",
    "    state_dict = checkpoint['state_dict']\n",
    "elif 'P_state' in checkpoint:\n",
    "    state_dict = checkpoint['P_state']\n",
    "else:\n",
    "    state_dict = checkpoint\n",
    "\n",
    "try:\n",
    "    in_features = model.fc.in_features\n",
    "except AttributeError:\n",
    "    in_features = None\n",
    "state_dict = cvt_state_dict(state_dict, bnNameCnt, in_features, num_classes=num_class)\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "# print('read checkpoint {}'.format(path_checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88d11d57-acc4-4c7a-a6f2-0b2405e72aef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [06:03<00:00,  1.90s/it]\n"
     ]
    }
   ],
   "source": [
    "# extract train long tail split features\n",
    "\n",
    "model.eval()\n",
    "train_LT_features = None\n",
    "train_LT_gt = []\n",
    "with torch.no_grad():\n",
    "    for data, target, _ in tqdm(train_loader_lt):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        feats = model.eval()(data, features=True)\n",
    "        if train_LT_features is None:\n",
    "            train_LT_features = feats.detach().cpu()\n",
    "        else:\n",
    "            train_LT_features = torch.cat((train_LT_features, feats.detach().cpu()), dim=0)\n",
    "        train_LT_gt += target.cpu().numpy().tolist()\n",
    "\n",
    "data_normed = LA.norm(train_LT_features.numpy(), 2, axis=-1)\n",
    "train_LT_features = train_LT_features.numpy() / data_normed.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c8263f8-a6be-4502-b776-7fa02e60fce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:38<00:00,  2.04s/it]\n"
     ]
    }
   ],
   "source": [
    "# extract train few-shot split features\n",
    "\n",
    "model.eval()\n",
    "train_FS_features = None\n",
    "train_FS_gt = []\n",
    "with torch.no_grad():\n",
    "    for data, target, _ in tqdm(train_loader_fs):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        feats = model.eval()(data, features=True)\n",
    "        if train_FS_features is None:\n",
    "            train_FS_features = feats.detach().cpu()\n",
    "        else:\n",
    "            train_FS_features = torch.cat((train_FS_features, feats.detach().cpu()), dim=0)\n",
    "        train_FS_gt += target.cpu().numpy().tolist()\n",
    "\n",
    "data_normed = LA.norm(train_FS_features.numpy(), 2, axis=-1)\n",
    "train_FS_features = train_FS_features.numpy() / data_normed.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10da7747-6bc5-4731-89bb-41ead91324cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [02:36<00:00,  1.99s/it]\n"
     ]
    }
   ],
   "source": [
    "# extract test features\n",
    "\n",
    "model.eval()\n",
    "test_features = None\n",
    "test_gt = []\n",
    "with torch.no_grad():\n",
    "    for data, target, _ in tqdm(test_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        feats = model.eval()(data, features=True)\n",
    "        if test_features is None:\n",
    "            test_features = feats.detach().cpu()\n",
    "        else:\n",
    "            test_features = torch.cat((test_features, feats.detach().cpu()), dim=0)\n",
    "        test_gt += target.cpu().numpy().tolist()\n",
    "        \n",
    "data_normed = LA.norm(test_features.numpy(), 2, axis=-1)\n",
    "test_features = test_features.numpy() / data_normed.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0612777e-6703-416b-8f0f-c7c6cdce577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_tmp = torch.cdist(torch.tensor(test_features), torch.tensor(train_LT_features))\n",
    "predicted = torch.argsort(dist_tmp, dim=1)\n",
    "sorted_dist_test_lt = predicted.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5e8e14b-56a7-4f1a-afec-3a3fc47af42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageNet-100 Evaluation\n",
      "KNN@1  38.38\n",
      "KNN@10 38.98\n",
      "FS     45.18\n",
      "LT     47.26\n"
     ]
    }
   ],
   "source": [
    "print(f'ImageNet-100 Evaluation')\n",
    "\n",
    "class_acc = []\n",
    "loc_gt = np.array(test_gt)\n",
    "loc_argsort = sorted_dist_test_lt\n",
    "train_loc_gt = np.array(train_LT_gt)\n",
    "for cl in range(num_class):\n",
    "    predictions = loc_argsort[loc_gt == cl, 0]\n",
    "    result = (train_loc_gt[predictions] == cl).sum() / (loc_gt == cl).sum()\n",
    "    class_acc.append(result)\n",
    "class_acc.append(np.mean(class_acc))\n",
    "print('KNN@1 ', f'{class_acc[-1]*100:.2f}')\n",
    "\n",
    "knn=10\n",
    "class_acc = []\n",
    "loc_gt = np.array(test_gt)\n",
    "loc_argsort = sorted_dist_test_lt\n",
    "train_loc_gt = np.array(train_LT_gt)\n",
    "for cl in range(num_class):\n",
    "    predict_mat = np.zeros(((loc_gt == cl).sum(), num_class))\n",
    "    predictions = loc_argsort[loc_gt == cl, :knn]\n",
    "    for cl2 in range(num_class):\n",
    "        result2 = (train_loc_gt[predictions] == cl2).sum(1)\n",
    "        predict_mat[:, cl2] = result2\n",
    "    result = (np.argmax(predict_mat, 1) == cl).sum() / (loc_gt == cl).sum()   \n",
    "    class_acc.append(result)\n",
    "class_acc.append(np.mean(class_acc))\n",
    "print('KNN@10', f'{class_acc[-1]*100:.2f}')\n",
    "\n",
    "local_data = train_FS_features\n",
    "local_gt = np.array(train_FS_gt)\n",
    "fs_svm = LinearSVC(random_state=42)\n",
    "fs_svm.fit(local_data, local_gt)\n",
    "local_test = test_features\n",
    "local_gt_test = np.array(test_gt)\n",
    "predictions = fs_svm.predict(local_test)\n",
    "acc = (predictions == local_gt_test).sum() / len(local_gt_test)\n",
    "print('FS    ', f'{acc * 100:.2f}')\n",
    "\n",
    "local_data = train_LT_features\n",
    "local_gt = np.array(train_LT_gt)\n",
    "local_counter = Counter(local_gt)\n",
    "np.random.seed(42)\n",
    "lt_svm = LinearSVC(random_state=42)\n",
    "lt_svm.fit(local_data, local_gt)\n",
    "predictions = lt_svm.predict(local_test)\n",
    "acc = (predictions == local_gt_test).sum() / len(local_gt_test)\n",
    "print('LT    ', f'{acc * 100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e230d80-fbba-43a6-a79a-6f47e67c1ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
